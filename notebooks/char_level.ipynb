{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "char_level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaNdwGw3HHsS",
        "outputId": "92c5f4f6-5587-463e-9a85-40ec2bf198fc"
      },
      "source": [
        "#for google drive only\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd ../content/drive/My\\ Drive/Code/HaikuBot/notebooks/\n",
        "\n",
        "# import nltk\n",
        "# nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Code/HaikuBot/notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T19:02:26.824342Z",
          "iopub.status.busy": "2021-06-01T19:02:26.823863Z",
          "iopub.status.idle": "2021-06-01T19:02:30.728326Z",
          "shell.execute_reply": "2021-06-01T19:02:30.726361Z",
          "shell.execute_reply.started": "2021-06-01T19:02:26.824279Z"
        },
        "id": "0QDOHAytHHsX"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys, os\n",
        "sys.path.append('../')\n",
        "import utils\n",
        "from utils.haiku_scrape import scrape_haiku, replace_all, detokenize, load_haiku, prepare_cl_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pickle import dump, load\n",
        "\n",
        "#TF,nltk, scikit\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJerv0lNHHsd"
      },
      "source": [
        "# Character level Haiku RNN\n",
        "\n",
        "Why this and the word level are \"tough\" tasks: haikus are very small, so the context or lookback window has to be a fraction of the haiku itself, otherwise it will \"leak\" into other haikus of the dataset.\n",
        "\n",
        "## Resources\n",
        "- [Jason](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n",
        "- [Khanrad](https://github.com/KhanradCoder/LearnKeras/blob/master/4.RNNs/TextGeneration.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T17:42:09.752845Z",
          "iopub.status.busy": "2021-06-01T17:42:09.748616Z",
          "iopub.status.idle": "2021-06-01T17:42:10.711763Z",
          "shell.execute_reply": "2021-06-01T17:42:10.710177Z",
          "shell.execute_reply.started": "2021-06-01T17:42:09.752664Z"
        },
        "id": "jXsEY-WbHHsf"
      },
      "source": [
        "h_set = load_haiku()\n",
        "h_set = h_set[:int(len(h_set)*0.6)] # accomodate colab RAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T18:53:26.160085Z",
          "iopub.status.busy": "2021-06-01T18:53:26.159586Z",
          "iopub.status.idle": "2021-06-01T18:53:26.356633Z",
          "shell.execute_reply": "2021-06-01T18:53:26.354885Z",
          "shell.execute_reply.started": "2021-06-01T18:53:26.160027Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOvz5n0yHHsi",
        "outputId": "74a60a89-54d4-4e4e-9eef-50654a8c850f"
      },
      "source": [
        "flattened = \" \".join(h_set).replace('  ',' ')\n",
        "chars = sorted(list(set(flattened)))\n",
        "char_to_id = {c:i for i,c in enumerate(chars)}\n",
        "n_chars = len(flattened)\n",
        "n_vocab = len(chars)\n",
        "print(f'total # chars: {n_chars} \\n # unique chars: {n_vocab}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total # chars: 497483 \n",
            " # unique chars: 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T18:55:23.824419Z",
          "iopub.status.busy": "2021-06-01T18:55:23.824128Z",
          "iopub.status.idle": "2021-06-01T18:55:28.026536Z",
          "shell.execute_reply": "2021-06-01T18:55:28.025398Z",
          "shell.execute_reply.started": "2021-06-01T18:55:23.824387Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4liVeac1HHsj",
        "outputId": "d155a9fa-9716-4899-fd17-65d200f90ca3"
      },
      "source": [
        "def prepare_cl_data(raw_text, n_chars, seq_length = 10):\n",
        "    \"\"\"prepares data for character level RNN\n",
        "    also returns non reshaped version of X for generation later\"\"\"\n",
        "    X_pre = [] # non reshaped id sequences\n",
        "    y = []\n",
        "    for i in range(0, n_chars - seq_length, 1):\n",
        "        _x = raw_text[i : i+seq_length]\n",
        "        if '$' in _x and _x.index('$') != len(_x)-1: #cutting off haiku data when they end\n",
        "            continue\n",
        "        _y = raw_text[i+seq_length]\n",
        "        X_pre.append([char_to_id[c] for c in _x])\n",
        "        y.append(char_to_id[_y])\n",
        "    train_size = len(X_pre)\n",
        "    print(f'train size: {train_size}')\n",
        "    \n",
        "    # reshape X to [samples, time_steps, features]\n",
        "    X = np.reshape(X_pre, (train_size, seq_length, 1))\n",
        "    X = X / float(n_vocab) # normalize\n",
        "    y = to_categorical(y)\n",
        "    return X_pre, X, y\n",
        "\n",
        "X_pre,X,y = prepare_cl_data(flattened, n_chars=n_chars, seq_length=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size: 436633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO5sFpRcJOr0",
        "outputId": "11b95018-1d85-42ec-fa91-9fc69a10dbde"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(436633, 10, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufaHIB-SHHsk",
        "outputId": "50318f2c-b84c-4811-b488-56aa92eef85a"
      },
      "source": [
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True),\n",
        "    Dropout(0.1),\n",
        "    LSTM(256),\n",
        "    Dropout(0.1),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(y.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_49 (LSTM)               (None, 10, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_50 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               25700     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 41)                4141      \n",
            "=================================================================\n",
            "Total params: 819,345\n",
            "Trainable params: 819,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmfoGjldHuuH",
        "outputId": "0c60f841-dc7e-428b-f65f-52f05436f753"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "filepath = '../models/cl_checkpoints/optimized-{epoch:02d}-{loss:.4f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=True, save_best_only=True)\n",
        "model.fit(X,y, epochs=50, batch_size=80, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6823/6823 [==============================] - 47s 6ms/step - loss: 2.3845\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.38447, saving model to ../models/cl_checkpoints/optimized-01-2.3845.hdf5\n",
            "Epoch 2/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 2.0304\n",
            "\n",
            "Epoch 00002: loss improved from 2.38447 to 2.03043, saving model to ../models/cl_checkpoints/optimized-02-2.0304.hdf5\n",
            "Epoch 3/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.8884\n",
            "\n",
            "Epoch 00003: loss improved from 2.03043 to 1.88840, saving model to ../models/cl_checkpoints/optimized-03-1.8884.hdf5\n",
            "Epoch 4/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.8049\n",
            "\n",
            "Epoch 00004: loss improved from 1.88840 to 1.80493, saving model to ../models/cl_checkpoints/optimized-04-1.8049.hdf5\n",
            "Epoch 5/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.7482\n",
            "\n",
            "Epoch 00005: loss improved from 1.80493 to 1.74818, saving model to ../models/cl_checkpoints/optimized-05-1.7482.hdf5\n",
            "Epoch 6/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.7033\n",
            "\n",
            "Epoch 00006: loss improved from 1.74818 to 1.70325, saving model to ../models/cl_checkpoints/optimized-06-1.7033.hdf5\n",
            "Epoch 7/50\n",
            "6823/6823 [==============================] - 39s 6ms/step - loss: 1.6711\n",
            "\n",
            "Epoch 00007: loss improved from 1.70325 to 1.67106, saving model to ../models/cl_checkpoints/optimized-07-1.6711.hdf5\n",
            "Epoch 8/50\n",
            "6823/6823 [==============================] - 39s 6ms/step - loss: 1.6394\n",
            "\n",
            "Epoch 00008: loss improved from 1.67106 to 1.63941, saving model to ../models/cl_checkpoints/optimized-08-1.6394.hdf5\n",
            "Epoch 9/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.6180\n",
            "\n",
            "Epoch 00009: loss improved from 1.63941 to 1.61802, saving model to ../models/cl_checkpoints/optimized-09-1.6180.hdf5\n",
            "Epoch 10/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.5993\n",
            "\n",
            "Epoch 00010: loss improved from 1.61802 to 1.59932, saving model to ../models/cl_checkpoints/optimized-10-1.5993.hdf5\n",
            "Epoch 11/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.5830\n",
            "\n",
            "Epoch 00011: loss improved from 1.59932 to 1.58303, saving model to ../models/cl_checkpoints/optimized-11-1.5830.hdf5\n",
            "Epoch 12/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.5669\n",
            "\n",
            "Epoch 00012: loss improved from 1.58303 to 1.56693, saving model to ../models/cl_checkpoints/optimized-12-1.5669.hdf5\n",
            "Epoch 13/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.5529\n",
            "\n",
            "Epoch 00013: loss improved from 1.56693 to 1.55287, saving model to ../models/cl_checkpoints/optimized-13-1.5529.hdf5\n",
            "Epoch 14/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.5412\n",
            "\n",
            "Epoch 00014: loss improved from 1.55287 to 1.54121, saving model to ../models/cl_checkpoints/optimized-14-1.5412.hdf5\n",
            "Epoch 15/50\n",
            "6823/6823 [==============================] - 38s 5ms/step - loss: 1.5299\n",
            "\n",
            "Epoch 00015: loss improved from 1.54121 to 1.52993, saving model to ../models/cl_checkpoints/optimized-15-1.5299.hdf5\n",
            "Epoch 16/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.5184\n",
            "\n",
            "Epoch 00016: loss improved from 1.52993 to 1.51835, saving model to ../models/cl_checkpoints/optimized-16-1.5184.hdf5\n",
            "Epoch 17/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.5083\n",
            "\n",
            "Epoch 00017: loss improved from 1.51835 to 1.50831, saving model to ../models/cl_checkpoints/optimized-17-1.5083.hdf5\n",
            "Epoch 18/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4990\n",
            "\n",
            "Epoch 00018: loss improved from 1.50831 to 1.49903, saving model to ../models/cl_checkpoints/optimized-18-1.4990.hdf5\n",
            "Epoch 19/50\n",
            "6823/6823 [==============================] - 38s 5ms/step - loss: 1.4914\n",
            "\n",
            "Epoch 00019: loss improved from 1.49903 to 1.49140, saving model to ../models/cl_checkpoints/optimized-19-1.4914.hdf5\n",
            "Epoch 20/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4846\n",
            "\n",
            "Epoch 00020: loss improved from 1.49140 to 1.48456, saving model to ../models/cl_checkpoints/optimized-20-1.4846.hdf5\n",
            "Epoch 21/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.4766\n",
            "\n",
            "Epoch 00021: loss improved from 1.48456 to 1.47659, saving model to ../models/cl_checkpoints/optimized-21-1.4766.hdf5\n",
            "Epoch 22/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.4699\n",
            "\n",
            "Epoch 00022: loss improved from 1.47659 to 1.46994, saving model to ../models/cl_checkpoints/optimized-22-1.4699.hdf5\n",
            "Epoch 23/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4610\n",
            "\n",
            "Epoch 00023: loss improved from 1.46994 to 1.46101, saving model to ../models/cl_checkpoints/optimized-23-1.4610.hdf5\n",
            "Epoch 24/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4576\n",
            "\n",
            "Epoch 00024: loss improved from 1.46101 to 1.45755, saving model to ../models/cl_checkpoints/optimized-24-1.4576.hdf5\n",
            "Epoch 25/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4518\n",
            "\n",
            "Epoch 00025: loss improved from 1.45755 to 1.45177, saving model to ../models/cl_checkpoints/optimized-25-1.4518.hdf5\n",
            "Epoch 26/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4463\n",
            "\n",
            "Epoch 00026: loss improved from 1.45177 to 1.44632, saving model to ../models/cl_checkpoints/optimized-26-1.4463.hdf5\n",
            "Epoch 27/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.4393\n",
            "\n",
            "Epoch 00027: loss improved from 1.44632 to 1.43932, saving model to ../models/cl_checkpoints/optimized-27-1.4393.hdf5\n",
            "Epoch 28/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4357\n",
            "\n",
            "Epoch 00028: loss improved from 1.43932 to 1.43575, saving model to ../models/cl_checkpoints/optimized-28-1.4357.hdf5\n",
            "Epoch 29/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4297\n",
            "\n",
            "Epoch 00029: loss improved from 1.43575 to 1.42970, saving model to ../models/cl_checkpoints/optimized-29-1.4297.hdf5\n",
            "Epoch 30/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4243\n",
            "\n",
            "Epoch 00030: loss improved from 1.42970 to 1.42426, saving model to ../models/cl_checkpoints/optimized-30-1.4243.hdf5\n",
            "Epoch 31/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.4208\n",
            "\n",
            "Epoch 00031: loss improved from 1.42426 to 1.42084, saving model to ../models/cl_checkpoints/optimized-31-1.4208.hdf5\n",
            "Epoch 32/50\n",
            "6823/6823 [==============================] - 39s 6ms/step - loss: 1.4149\n",
            "\n",
            "Epoch 00032: loss improved from 1.42084 to 1.41493, saving model to ../models/cl_checkpoints/optimized-32-1.4149.hdf5\n",
            "Epoch 33/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4116\n",
            "\n",
            "Epoch 00033: loss improved from 1.41493 to 1.41161, saving model to ../models/cl_checkpoints/optimized-33-1.4116.hdf5\n",
            "Epoch 34/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4087\n",
            "\n",
            "Epoch 00034: loss improved from 1.41161 to 1.40867, saving model to ../models/cl_checkpoints/optimized-34-1.4087.hdf5\n",
            "Epoch 35/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.4042\n",
            "\n",
            "Epoch 00035: loss improved from 1.40867 to 1.40420, saving model to ../models/cl_checkpoints/optimized-35-1.4042.hdf5\n",
            "Epoch 36/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.4005\n",
            "\n",
            "Epoch 00036: loss improved from 1.40420 to 1.40048, saving model to ../models/cl_checkpoints/optimized-36-1.4005.hdf5\n",
            "Epoch 37/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3954\n",
            "\n",
            "Epoch 00037: loss improved from 1.40048 to 1.39540, saving model to ../models/cl_checkpoints/optimized-37-1.3954.hdf5\n",
            "Epoch 38/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.3930\n",
            "\n",
            "Epoch 00038: loss improved from 1.39540 to 1.39303, saving model to ../models/cl_checkpoints/optimized-38-1.3930.hdf5\n",
            "Epoch 39/50\n",
            "6823/6823 [==============================] - 37s 5ms/step - loss: 1.3901\n",
            "\n",
            "Epoch 00039: loss improved from 1.39303 to 1.39014, saving model to ../models/cl_checkpoints/optimized-39-1.3901.hdf5\n",
            "Epoch 40/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3861\n",
            "\n",
            "Epoch 00040: loss improved from 1.39014 to 1.38612, saving model to ../models/cl_checkpoints/optimized-40-1.3861.hdf5\n",
            "Epoch 41/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3839\n",
            "\n",
            "Epoch 00041: loss improved from 1.38612 to 1.38392, saving model to ../models/cl_checkpoints/optimized-41-1.3839.hdf5\n",
            "Epoch 42/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3801\n",
            "\n",
            "Epoch 00042: loss improved from 1.38392 to 1.38010, saving model to ../models/cl_checkpoints/optimized-42-1.3801.hdf5\n",
            "Epoch 43/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3774\n",
            "\n",
            "Epoch 00043: loss improved from 1.38010 to 1.37741, saving model to ../models/cl_checkpoints/optimized-43-1.3774.hdf5\n",
            "Epoch 44/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3735\n",
            "\n",
            "Epoch 00044: loss improved from 1.37741 to 1.37352, saving model to ../models/cl_checkpoints/optimized-44-1.3735.hdf5\n",
            "Epoch 45/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3716\n",
            "\n",
            "Epoch 00045: loss improved from 1.37352 to 1.37157, saving model to ../models/cl_checkpoints/optimized-45-1.3716.hdf5\n",
            "Epoch 46/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3690\n",
            "\n",
            "Epoch 00046: loss improved from 1.37157 to 1.36901, saving model to ../models/cl_checkpoints/optimized-46-1.3690.hdf5\n",
            "Epoch 47/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3653\n",
            "\n",
            "Epoch 00047: loss improved from 1.36901 to 1.36534, saving model to ../models/cl_checkpoints/optimized-47-1.3653.hdf5\n",
            "Epoch 48/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3624\n",
            "\n",
            "Epoch 00048: loss improved from 1.36534 to 1.36241, saving model to ../models/cl_checkpoints/optimized-48-1.3624.hdf5\n",
            "Epoch 49/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3606\n",
            "\n",
            "Epoch 00049: loss improved from 1.36241 to 1.36058, saving model to ../models/cl_checkpoints/optimized-49-1.3606.hdf5\n",
            "Epoch 50/50\n",
            "6823/6823 [==============================] - 38s 6ms/step - loss: 1.3583\n",
            "\n",
            "Epoch 00050: loss improved from 1.36058 to 1.35832, saving model to ../models/cl_checkpoints/optimized-50-1.3583.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f373bebc050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHcvgg7lHHsl"
      },
      "source": [
        "model.load_weights(\"../models/cl_checkpoints/optimized-50-1.3583.hdf5\")\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "id_to_char = {i:c for i,c in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FRb_PdMHHsm"
      },
      "source": [
        "def generate_sequences(model, Xpre, seed='AUTO'):\n",
        "    if seed == 'AUTO':\n",
        "        start = np.random.randint(0, len(Xpre)-1)\n",
        "        sequence = Xpre[start]\n",
        "        print(sequence)\n",
        "        print(f'Auto seed: {\"\".join([id_to_char[v] for v in sequence])}')\n",
        "    else:\n",
        "        sequence = [char_to_id[c] for c in seed]\n",
        "    end = False\n",
        "    out = \"\"\n",
        "    # while not end:\n",
        "    for i in range(100):\n",
        "        x = np.reshape(sequence, (1, len(sequence), 1))\n",
        "        x = x/float(n_vocab)\n",
        "        prediction = model.predict(x, verbose=False)\n",
        "        index = np.argmax(prediction)\n",
        "        result = id_to_char[index]\n",
        "        if result == '$':\n",
        "            end = True \n",
        "        sequence.append(index)\n",
        "        sequence = sequence[1:len(sequence)]\n",
        "        out += result\n",
        "    #out = [id_to_char[v] for v in sequence]\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "GjcGaWjuHHsn",
        "outputId": "6a28901c-a138-4580-b148-ffde1ab5eecd"
      },
      "source": [
        "generate_sequences(model, Xpre=X_pre, seed=\"this is a stanza / about somethin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"g / movem i fall rowring all oakes meak / wornd is alome / i can't iosende / it alr sast instinn is \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGomZ7lLaYaY"
      },
      "source": [
        "`\"The stars\"` appears in oscillatory output for short input sequences, maybe due to its presence in the training set, resulting in overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af_VdWKIXjjx",
        "outputId": "978ee817-1a1c-4958-e10f-c6b6f4c847e9"
      },
      "source": [
        "for h in h_set:\n",
        "  if 'the stars' in h:\n",
        "    print(h)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i can float away / into the deep dark abyss / welcomed by the stars $\n",
            "the shine of the moon / and the glimmer of the stars / damn mortality $\n",
            "the stars are smeared red /  the old ones arrive /  our very last sunrise $\n",
            "in limpid silver / she shines bright amongst the stars / down here a dog barks $\n",
            "the cityscape shifts /  when i remove my glasses /  the stars stay the same $\n",
            "i'd bleed myself dry / and rename the stars for you / just to kiss you once $\n",
            "something like a dream /  lost in the stars of your eyes /  that brought be back to older days $\n",
            "the stars are abode  / to sky deities aloft / pure imagination $\n",
            "crackling fires glowing / embers rise to meet the stars / tin cups clink with joy $\n",
            "sleeping mountain dreams /  cloaked by the whispering rain /  waiting for the stars $\n",
            "the stars have aligned / the great heroes have returned / they are twilight force $\n",
            "a conversation / we had between the daisies / what do the stars mean $\n",
            "the bright sun sets far / further than the stars and skies / even birds can't spy $\n",
            "stuck in the starship / slimed eyes teeth wildly clacking / the plagued have found us $\n",
            "i speak to the stars /  about my deepest secrets /  when will they speak back $\n",
            "the moon shines brightly / the stars twinkle in the sky / the sea laps the shore $\n",
            "i look at the stars / looking down on me moving slow / drops now pouring rain $\n",
            "illuminating / the dark space between the stars / the silver moon sails $\n",
            "do i wish i could / or is mediocrity / my shoot for the stars $\n",
            "crossing open sea / sailing with a strong night wind / guided by the stars $\n",
            "as the stars slide by / and the years gather their pace / my love keeps growing $\n",
            "when i was younger / i told the moon and the stars / all of my secrets $\n",
            "your face a new moon / i know only your shadow / blotting out the stars $\n",
            "spider's eyes / in the grass shimmer / like the stars $\n",
            "the stars have gone out / some sleepy song of robins / give me ears to hear $\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7eUuGRoZJnW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}